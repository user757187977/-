### CPU usage vs CPU load

1. CPU usage: cpu 利用率, 程序对 CPU 时间片的占用情况.
2. CPU load: 表示 CPU 的负载, 是一段时间内 CPU 正在处理以及等待 CPU 处理的进程数之和的统计信息. 可以说是 CPU 使用队列的长度统计信息.

### 什么时候出现 CPU load 高

1. 需要 CPU 参与的线程数过高, 而 CPU 核心较少, 用于 CPU 上下文切换的时间已经高于执行时间.
2. 比如单核心 CPU 场景, 使用多线程进行 死循环i++ 操作.

### 什么时候 full GC

### 内存泄露遇到没

1. 先说什么才是内存泄露
2. 我们有哪些线索可以说明, 此刻我们遇到了内存泄露的问题
3. 内存泄露的解决办法

### 线上问题

## 服务问题

1. arthas 打火焰图
    1. profiler start --event itimer 由于 k8s 的 perf_event_open 默认是未开启的状态, 在容器内使用会有权限问题. 此时可以使用 itimer 事件来采样, 此事件与 cpu
       采样类似, 但是不需要 perf_events 支持, 缺点是无法统计内核的堆栈性能.
    2. 火焰图 Y 轴: 表示 栈 深度, X 轴: 抽样数, 如果一个函数在 x 轴占据的宽度越宽, 就表示它被抽到的次数多, 即执行的时间长. 注意, x轴不代表时间, 而是所有的调用栈合并后, 按字母顺序排列的.
    3. 火焰图就是看顶层的哪个函数占据的宽度最大. 只要有平顶 (plateaus), 就表示该函数可能存在性能问题. 颜色没有实际意义, 只是随机选取用于栈帧之间相互区分.

## K8s

K8s 驱逐了我们执行成功的 job, 导致我们在下一次查询窗口内, 没办法获取 job 的状态, 所以任务 hang 死 目前我们是间隔 2s 查询回来 k8s 状态, 来判断实例成功 OR 失败 OR 运行中 但是有一种情况, 比如:
我们实例 00:00:00.000 执行完成之后立即被驱逐 结果我们在 00:00:02 没办法查询到被驱逐的 container 的状态, 所以我们没办法确认这个实例的状态 解决办法就是 推拉结合 + watch 机制

## redis

1. redis-proxy CPU 100%
    1. 原因: 错误的代码实现, for(无限) redis.setKey; redis.expireKey;
    2. 修改方式:
        1. 利用 redis 的 pipeline, 把多条数据一次写入;
        2. 错误的配置, 没有使用连接池, 池化技术;
        3. 我们的配置没有做到探活;

## kafka 雪崩

在 hdfs 迁移过程中, 对实时任务产生影响, 比如现在是 10 点, 按理说 8 点的实时任务需要在 8 点操作, 10 点的实时任务在 10 点操作, 但是 10 点操作了 10 点的实时数据之后操作了 8 点的实时任务, 这个时候
kafka 会认为 8 点才是真正的热点数据, 于是全部加载到堆外内存以用于零拷贝, 于是把 10 点真正的热点数据进行了 GC, 但是真正需要的是 10 点的数据, 于是走了磁盘把 10 点的数据拉回来, 此时进入一种循环状态, 8 点
10 点的数据, 分别认为自己是热点数据, 分别要加载到堆外内存中, 所以互相 GC 也互相没办法到堆外内存, 于是此时磁盘写满.